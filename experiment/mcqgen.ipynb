{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439269.50s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting openai\n",
      "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from openai) (2.6.3)\n",
      "Requirement already satisfied: sniffio in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.7 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback2 as traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"openai_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=key, model_name=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x12851d9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x128528c10>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/Response.json\") as f:\n",
    "    response_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'multiple choice questions',\n",
       "  'options': {'a': 'choice here',\n",
       "   'b': 'choice here',\n",
       "   'c': 'choice here',\n",
       "   'd': 'choice here'},\n",
       "  'correct': 'correct answer'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_gen_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_gen_chain = LLMChain(llm=llm, prompt=quiz_gen_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_review_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\",\"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_review_chain = LLMChain(llm=llm, prompt=quiz_review_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_chain = SequentialChain(chains=[quiz_gen_chain,quiz_review_chain],input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],output_variables=[\"quiz\",\"review\"],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/data.txt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/nishu/genAIMCQGeneraror/GenAiMCQGenerator/data.txt\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path,\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM® watsonx.ai™ AI studio is part of the IBM watsonx™ AI and data platform, bringing together new generative AI capabilities powered by foundation models and traditional machine learning (ML) into a powerful studio spanning the AI lifecycle. Tune and guide models with your enterprise data to meet your needs with easy-to-use tools for building and refining performant prompts. With watsonx.ai, you can build AI applications in a fraction of the time and with a fraction of the data. Watsonx.ai offers:\\n\\nMulti-model variety and flexibility: Choose from IBM-developed, open-source and third-party models, or build your own model.\\nDifferentiated client protection: IBM stands behind IBM-developed models and indemnifies the client against third-party IP claims.\\nEnd-to-end AI governance: Enterprises can scale and accelerate the impact of AI with trusted data across the business, using data wherever it resides.\\nHybrid, multi-cloud deployments: IBM provides the flexibility to integrate and deploy your AI workloads into your hybrid-cloud stack of choice.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cce71c3a4a13ff0624382b3a2bd4e681c8fe7f684a2dfb71b275ee2aa49ec483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
